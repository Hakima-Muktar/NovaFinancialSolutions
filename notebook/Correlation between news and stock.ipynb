{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fc6468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from scipy import stats\n",
    "from textblob import TextBlob\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "\n",
    "project_root = Path().resolve().parent\n",
    "if str(project_root) not in sys.path:\n",
    "    sys.path.append(str(project_root))\n",
    "\n",
    "from src.features.sentiment_correlation import (\n",
    "    load_data,\n",
    "    normalize_dates,\n",
    "    analyze_sentiment,\n",
    "    calculate_daily_returns,\n",
    "    aggregate_daily_sentiment,\n",
    "    merge_sentiment_with_returns,\n",
    "    calculate_correlation\n",
    ")\n",
    "\n",
    "from src.visualization.sentiment_visualization import (\n",
    "    plot_sentiment_returns_scatter,\n",
    "    plot_sentiment_returns_time_series,\n",
    "    plot_lagged_correlations,\n",
    "    plot_sentiment_distribution\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ff47b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = project_root / \"src\"\n",
    "news_path = data_dir / \"data\" / \"news\"/\"raw_analyst_ratings.csv\"\n",
    "\n",
    "# Choose a stock ticker to analyze\n",
    "ticker = \"AAPL\"  \n",
    "stock_path = data_dir / f\"{ticker}.csv\"\n",
    "\n",
    "# Load the data\n",
    "try:\n",
    "    news_df, stock_df = load_data(str(news_path), str(stock_path))\n",
    "    print(f\"News data shape: {news_df.shape}\")\n",
    "    print(f\"Stock data shape: {stock_df.shape}\")\n",
    "    \n",
    "    print(\"\\nNews data preview:\")\n",
    "    display(news_df.head())\n",
    "    \n",
    "    print(f\"\\n{ticker} stock data preview:\")\n",
    "    display(stock_df.head())\n",
    "except Exception as e:\n",
    "    print(f\"Error loading data: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911fa70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'news_df' not in locals() or 'stock_df' not in locals():\n",
    "    data_dir = project_root / \"src\"\n",
    "    news_path = data_dir / \"data\" / \"raw_analyst_ratings.csv\"\n",
    "    \n",
    "    # Choose a stock ticker to analyze\n",
    "    ticker = \"AAPL\"  # You can change this to any available ticker\n",
    "    stock_path = data_dir / \"historical_data\" / f\"{ticker}.csv\"\n",
    "\n",
    "    print(\"Creating sample data for demonstration...\")\n",
    "    \n",
    "    # Sample news data\n",
    "    news_df = pd.DataFrame({\n",
    "        'date': pd.date_range(start='2023-01-01', periods=30),\n",
    "        'headline': [\n",
    "            f\"{ticker} announces new product line\",\n",
    "            f\"{ticker} beats earnings expectations\",\n",
    "            f\"{ticker} stock drops on market concerns\",\n",
    "            f\"Analysts upgrade {ticker} to buy\",\n",
    "            f\"{ticker} faces regulatory scrutiny\"\n",
    "        ] * 6\n",
    "    })\n",
    "    \n",
    "    # Sample stock data\n",
    "    stock_df = pd.DataFrame({\n",
    "        'Date': pd.date_range(start='2023-01-01', periods=50),\n",
    "        'Open': np.random.uniform(150, 180, 50),\n",
    "        'High': np.random.uniform(160, 190, 50),\n",
    "        'Low': np.random.uniform(140, 170, 50),\n",
    "        'Close': np.random.uniform(145, 185, 50),\n",
    "        'Volume': np.random.randint(1000000, 5000000, 50)\n",
    "    })\n",
    "    \n",
    "    print(\"Sample data created successfully\")\n",
    "\n",
    "# Now proceed with normalization\n",
    "# Normalize dates\n",
    "news_df, stock_df = normalize_dates(news_df, stock_df, 'date', 'Date')\n",
    "\n",
    "# Check date ranges\n",
    "print(f\"News data date range: {news_df['date'].min()} to {news_df['date'].max()}\")\n",
    "print(f\"Stock data date range: {stock_df['Date'].min()} to {stock_df['Date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958739bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we need to filter by stock\n",
    "if 'stock' in news_df.columns:\n",
    "    # Filter to only include news for our selected ticker\n",
    "    ticker_news_df = news_df[news_df['stock'] == ticker].copy()\n",
    "    print(f\"Found {len(ticker_news_df)} news items for {ticker}\")\n",
    "else:\n",
    "    # If no stock column, use all news\n",
    "    ticker_news_df = news_df.copy()\n",
    "    print(\"No stock column found in news data, using all news items\")\n",
    "\n",
    "# Display a few headlines\n",
    "if 'headline' in ticker_news_df.columns:\n",
    "    print(\"\\nSample headlines:\")\n",
    "    for headline in ticker_news_df['headline'].head(5).tolist():\n",
    "        print(f\"- {headline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c428be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze sentiment\n",
    "news_with_sentiment = analyze_sentiment(ticker_news_df, 'headline')\n",
    "\n",
    "# Display results\n",
    "display(\n",
    "    news_with_sentiment[\n",
    "        ['headline', 'polarity', 'subjectivity', 'sentiment_category']\n",
    "    ].head(10)\n",
    ")\n",
    "\n",
    "# Summarize sentiment categories\n",
    "sentiment_counts = news_with_sentiment['sentiment_category'].value_counts()\n",
    "display(sentiment_counts)\n",
    "\n",
    "# Plot sentiment distribution\n",
    "plot_sentiment_distribution(\n",
    "    news_with_sentiment,\n",
    "    sentiment_col='polarity',\n",
    "    title=f'Distribution of {ticker} News Sentiment'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9652f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily returns\n",
    "stock_with_returns = calculate_daily_returns(stock_df, 'Date', 'Close')\n",
    "\n",
    "# Display results\n",
    "print(\"Stock returns calculation:\")\n",
    "display(stock_with_returns[['Date', 'Close', 'daily_return']].head(10))\n",
    "\n",
    "# Summarize returns\n",
    "returns_stats = stock_with_returns['daily_return'].describe()\n",
    "print(\"\\nReturns statistics:\")\n",
    "display(returns_stats)\n",
    "\n",
    "# Plot returns distribution\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(stock_with_returns['daily_return'], kde=True)\n",
    "plt.title(f'{ticker} Daily Returns Distribution')\n",
    "plt.xlabel('Daily Return')\n",
    "plt.ylabel('Frequency')\n",
    "plt.axvline(x=0, color='r', linestyle='--')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ba0797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate daily sentiment\n",
    "daily_sentiment = aggregate_daily_sentiment(news_with_sentiment, 'date')\n",
    "\n",
    "# Display results\n",
    "print(\"Daily sentiment aggregation:\")\n",
    "display(daily_sentiment.head(10))\n",
    "\n",
    "# Show days with multiple articles\n",
    "multi_article_days = daily_sentiment[daily_sentiment['article_count'] > 1]\n",
    "print(f\"\\nDays with multiple articles: {len(multi_article_days)}\")\n",
    "if len(multi_article_days) > 0:\n",
    "    display(multi_article_days.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27054b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge sentiment with returns\n",
    "merged_df = merge_sentiment_with_returns(daily_sentiment, stock_with_returns, 'date', 'Date')\n",
    "\n",
    "# Display results\n",
    "print(f\"Merged data shape: {merged_df.shape}\")\n",
    "print(\"Merged sentiment and returns data:\")\n",
    "display(merged_df.head(10))\n",
    "\n",
    "# Check for any date misalignment\n",
    "print(f\"\\nSentiment dates without matching returns: {len(daily_sentiment) - len(merged_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73b40fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation\n",
    "correlation_results = calculate_correlation(merged_df)\n",
    "\n",
    "# Display results\n",
    "print(\"Correlation Results:\")\n",
    "print(f\"Correlation coefficient: {correlation_results['correlation']:.3f}\")\n",
    "print(f\"P-value: {correlation_results['p_value']:.3f}\")\n",
    "print(f\"Statistically significant: {correlation_results['significant']}\")\n",
    "print(f\"\\nInterpretation:\\n{correlation_results['interpretation']}\")\n",
    "\n",
    "# Print lagged correlation summary\n",
    "print(\"\\nLagged Correlations (sentiment leading returns):\")\n",
    "for lag_data in correlation_results['lagged_correlations']:\n",
    "    lag = lag_data['lag']\n",
    "    corr = lag_data['sentiment_leading_returns_corr']\n",
    "    p_val = lag_data['sentiment_leading_returns_p']\n",
    "    sig = \"significant\" if p_val < 0.05 else \"not significant\"\n",
    "    print(f\"  Lag {lag} day(s): {corr:.3f} (p={p_val:.3f}, {sig})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1854da82",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sentiment_returns_time_series(\n",
    "    merged_df,\n",
    "    title=f'Sentiment and Returns Over Time for {ticker}'\n",
    ")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2106d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- MISSING THIS ---\n",
    "import matplotlib.pyplot as plt \n",
    "# --------------------\n",
    "\n",
    "# Time series plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "plot_sentiment_returns_time_series(merged_df, title=f'Sentiment and Returns Over Time for {ticker}')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23203ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time series plot\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(12, 6))\n",
    "plot_sentiment_returns_time_series(merged_df, title=f'Sentiment and Returns Over Time for {ticker}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d6c606",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lagged correlations\n",
    "plt.figure(figsize=(12, 6))\n",
    "plot_lagged_correlations(correlation_results, title=f'Lagged Correlations for {ticker}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c6d2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to analyze multiple stocks\n",
    "def analyze_multiple_stocks(tickers):\n",
    "    results = {}\n",
    "    \n",
    "    for ticker in tickers:\n",
    "        stock_path = data_dir / f\"{ticker}_historical_data.csv\"\n",
    "        \n",
    "        if not os.path.exists(stock_path):\n",
    "            print(f\"Stock data file not found for {ticker}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Load data\n",
    "            news_df_tmp, stock_df_tmp = load_data(str(news_path), str(stock_path))\n",
    "            \n",
    "            # Filter news for this ticker if needed\n",
    "            if 'stock' in news_df_tmp.columns:\n",
    "                ticker_news = news_df_tmp[news_df_tmp['stock'] == ticker].copy()\n",
    "                if len(ticker_news) == 0:\n",
    "                    print(f\"No news found for {ticker}\")\n",
    "                    continue\n",
    "            else:\n",
    "                ticker_news = news_df_tmp.copy()\n",
    "            \n",
    "            # Normalize dates\n",
    "            ticker_news, stock_df_tmp = normalize_dates(ticker_news, stock_df_tmp, 'date', 'Date')\n",
    "            \n",
    "            # Analyze sentiment\n",
    "            news_with_sentiment = analyze_sentiment(ticker_news, 'headline')\n",
    "            \n",
    "            # Calculate returns\n",
    "            stock_with_returns = calculate_daily_returns(stock_df_tmp, 'Date', 'Close')\n",
    "            \n",
    "            # Aggregate daily sentiment\n",
    "            daily_sentiment = aggregate_daily_sentiment(news_with_sentiment, 'date')\n",
    "            \n",
    "            # Merge sentiment with returns\n",
    "            merged_df = merge_sentiment_with_returns(daily_sentiment, stock_with_returns, 'date', 'Date')\n",
    "            \n",
    "            # Calculate correlation\n",
    "            correlation_results = calculate_correlation(merged_df)\n",
    "            correlation_results['data'] = merged_df\n",
    "            \n",
    "            # Store results\n",
    "            results[ticker] = correlation_results\n",
    "            \n",
    "            print(f\"{ticker}: Correlation = {correlation_results['correlation']:.3f}, \"\n",
    "                 f\"p-value = {correlation_results['p_value']:.3f}, \"\n",
    "                 f\"significant = {correlation_results['significant']}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error analyzing {ticker}: {str(e)}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Analyze multiple stocks\n",
    "print(\"Analyzing correlation for multiple stocks...\\n\")\n",
    "stock_tickers = [\"AAPL\", \"AMZN\", \"GOOG\", \"META\", \"MSFT\", \"NVDA\", \"TSLA\"]\n",
    "multi_stock_results = analyze_multiple_stocks(stock_tickers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433b8e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare correlations across stocks\n",
    "if multi_stock_results:\n",
    "    # Extract correlation data\n",
    "    tickers = list(multi_stock_results.keys())\n",
    "    correlations = [multi_stock_results[ticker]['correlation'] for ticker in tickers]\n",
    "    p_values = [multi_stock_results[ticker]['p_value'] for ticker in tickers]\n",
    "    \n",
    "    # Create a DataFrame for comparison\n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Ticker': tickers,\n",
    "        'Correlation': correlations,\n",
    "        'P-Value': p_values,\n",
    "        'Significant': [p < 0.05 for p in p_values]\n",
    "    })\n",
    "    \n",
    "    # Sort by correlation strength\n",
    "    comparison_df = comparison_df.sort_values('Correlation', key=abs, ascending=False)\n",
    "    \n",
    "    print(\"Correlation comparison across stocks:\")\n",
    "    display(comparison_df)\n",
    "    \n",
    "    # Create bar chart\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    colors = ['green' if p < 0.05 else 'gray' for p in comparison_df['P-Value']]\n",
    "    \n",
    "    plt.bar(comparison_df['Ticker'], comparison_df['Correlation'], color=colors)\n",
    "    plt.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    plt.title('Correlation between News Sentiment and Stock Returns')\n",
    "    plt.xlabel('Stock Ticker')\n",
    "    plt.ylabel('Pearson Correlation Coefficient')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add correlation values on top of bars\n",
    "    for i, v in enumerate(comparison_df['Correlation']):\n",
    "        plt.text(i, v + (0.01 if v >= 0 else -0.03), \n",
    "                f'{v:.3f}', \n",
    "                ha='center', va='bottom' if v >= 0 else 'top')\n",
    "    \n",
    "    # Add a legend\n",
    "    from matplotlib.patches import Patch\n",
    "    legend_elements = [\n",
    "        Patch(facecolor='green', label='Statistically Significant (p<0.05)'),\n",
    "        Patch(facecolor='gray', label='Not Significant')\n",
    "    ]\n",
    "    plt.legend(handles=legend_elements, loc='best')\n",
    "    \n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No results to compare.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ddf9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from textblob import TextBlob\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf58385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load news data\n",
    "news = pd.read_csv(\"../data/news/raw_analyst_ratings.csv\")\n",
    "news.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670da254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load stock data for apple\n",
    "apple=pd.read_csv(\"../data/finance/AAPL.csv\")\n",
    "apple.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ba68be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate sentiment polarity (-1 to 1)\n",
    "def get_sentiment(text):\n",
    "    return TextBlob(text).sentiment.polarity\n",
    "\n",
    "news[\"Sentiment\"] = news[\"headline\"].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce9b5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate daily average sentiment\n",
    "apple[\"Daily_Return\"] = apple[\"Close\"].pct_change()\n",
    "apple = apple[1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f61a7020",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate sentiment by date\n",
    "daily_sentiment = news.groupby(\"date\")[\"Sentiment\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9959bd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(\n",
    "    apple,\n",
    "    daily_sentiment,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37136829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate correlation\n",
    "import matplotlib.pyplot as plt\n",
    "correlation = merged_df[\"Daily_Return\"].corr(merged_df[\"Sentiment\"])\n",
    "# Plot as a bar\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.bar(\"Apple\", correlation, color=\"skyblue\")\n",
    "plt.y(-1, 1)\n",
    "plt.ylabel(\"Correlation\")\n",
    "plt.title(\"Correlation between News Sentiment & Stock Returns\")\n",
    "plt.axhline(0, color='black', linewidth=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700afcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots(figsize=(12,6))\n",
    "ax1.set_xlabel(\"Date\")\n",
    "ax1.set_ylabel(\"Daily Return\", color=\"blue\")\n",
    "ax1.plot(merged_df.index, merged_df[\"Daily_Return\"], color=\"blue\", label=\"Daily Return\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=\"blue\")\n",
    "ax2 = ax1.twinx()\n",
    "ax2.set_ylabel(\"Sentiment\", color=\"orange\")\n",
    "ax2.plot(merged_df.index, merged_df[\"Sentiment\"], color=\"orange\", label=\"Sentiment\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"orange\")\n",
    "fig.tight_layout()\n",
    "plt.title(\"Daily Stock Returns vs News Sentiment\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
